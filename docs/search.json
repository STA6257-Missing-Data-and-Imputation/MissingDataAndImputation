[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This is the group project for Advanced Statistical Modeling (STA6257) where we will explore how to use statistical methods to handle missing data in a dataset with a practice called imputation. Our team consists of Yoseling Gomez, Clayton Carpenter, and Stesh Davis-Lewis.\nPlease use the sidebar to navigate our projects pages.\nThe dataset we will be using is palmerpenguins (Horst, Hill, and Gorman 2020)\n\n\n\n\n\n(Horst, Hill, and Gorman 2020) Artwork by @allison_horst\n\n\n\n\nReferences\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020. “Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data.” https://doi.org/10.5281/zenodo.3960218."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "",
    "section": "",
    "text": "Yoseling Gomez\nClayton Carpenter\nStesh Davis-Lewis"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1. Introduction",
    "section": "",
    "text": "As much as researchers may attempt to eliminate or reduce missing values, datasets are rarely, if ever, perfect, which can impact the legitimacy and reliability of the results obtained. There are four main reasons for missing data: missing completely at random, missing at random, missing depending on unobserved predictors, and missingness that depends on the missing value itself.\nWhen data is missing in a dataset, it can be handled in two ways. First would be to simply delete the missing data from the dataset. This is generally the best method if the data is missing at random and makes up for a small amount of the larger dataset. If the data is not missing at random, or if deleting it would remove a substantial amount of the data, there is a statistical technique to handle missing data known as “imputation.” The most common type of imputation is single and multiple. “In single imputation, imputed values are considered as actual values. Single imputation ignores the fact that the actual value cannot be predicted for sure by any imputation method. Single imputation based methods do not consider the uncertainty of the imputed values. Instead, they recognize the imputed values as actual values in subsequent analysis.” (Khan and Hoque 2020) Single imputation replaces missing values by using multiple methods, such as replacing the missing value by copying the previous participants’ value, copying over the worst value in the data set, or calculating the mean for the variable. With a single imputation, there is no distinction between observed and imputed values, which could lead to bias, influenced by outliers, can spread errors, no way to detect the imputed values, and this methodology cannot be used for complex data. Despite these drawbacks, simple imputation is one of the most popular types of imputation due to its simplicity and status as the default imputation method in many statistical packages. (Zhang 2016)"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2. Data",
    "section": "",
    "text": "This project will focus on the penguin dataset in the “palmerpenguin” package (Horst, Hill, and Gorman 2020) from R studio. The penguins’ dataset is comprised of 8 columns and 344 rows based on data collected on three different species of penguins in Palmer Archipelago, Antarctica. This dataset is fairly clean, and this is important for comparison purposes. In this instance, there are only 11 NA values, which is 3% of the entire dataset. During the analysis, we will be removing parts of the dataset and implementing data imputation methodology to compare the accuracy between the actual values in the dataset and the calculated values we have created using different methodologies."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "4. Analysis",
    "section": "",
    "text": "To demonstrate the benefits of imputation, we will create missingness in a predictor variable and create a model by excluding the missing data. Then we will perform imputation on the dataset and recreate the model to see if there is a difference in performance. Before we perform imputations on the penguins (Horst, Hill, and Gorman 2020) dataset, first the data must be cleaned to omit all incomplete records so we can have the actual values to compare our imputations against. The code block below demonstrates the penguins dataset that we will be using, cleaning the incomplete records, and displays the correlation using the ggplot2 (Wickham 2016) package between body_mass_g and flipper_legth_mm that we will be using to construct a model before and after imputation of missing data.\n\nlibrary(readr)\nlibrary(missMethods)\nlibrary(simputation)\nlibrary(ggplot2)\n\nset.seed(1) \n\npenguins <- readr::read_csv('penguins.csv')\n\n\npenguin_rows_with_na <- penguins[!complete.cases(penguins), ]\nprint(penguin_rows_with_na)\n\n# A tibble: 11 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl>\n 1 Adelie  Torgersen           NA            NA                  NA          NA\n 2 Adelie  Torgersen           34.1          18.1               193        3475\n 3 Adelie  Torgersen           42            20.2               190        4250\n 4 Adelie  Torgersen           37.8          17.1               186        3300\n 5 Adelie  Torgersen           37.8          17.3               180        3700\n 6 Adelie  Dream               37.5          18.9               179        2975\n 7 Gentoo  Biscoe              44.5          14.3               216        4100\n 8 Gentoo  Biscoe              46.2          14.4               214        4650\n 9 Gentoo  Biscoe              47.3          13.8               216        4725\n10 Gentoo  Biscoe              44.5          15.7               217        4875\n11 Gentoo  Biscoe              NA            NA                  NA          NA\n# ℹ 2 more variables: sex <chr>, year <dbl>\n\npenguins_filtered <- na.omit(penguins)\n\n\nggplot(penguins_filtered, aes(body_mass_g, flipper_length_mm)) + \n  geom_count() + \n  geom_smooth(method='lm')\n\n\n\n\nIn the code block below, we will create 50% missing at random data in the column flipper_length_mm using the missMethods (Rockel 2022) package. Then we will create a linear regression to display the r-squared that would be achieved without performing any imputation on the data set.\n\npenguins_missing <- delete_MCAR(penguins,0.5,\"flipper_length_mm\")\n\nregg = lm(body_mass_g~ flipper_length_mm, data = penguins_missing, na.action=na.omit) \nprint(paste(summary(regg)$adj.r.squared, \"is the R-Squared for the linear model where missing values are excluded from the dataset.\"))\n\n[1] \"0.756874976743334 is the R-Squared for the linear model where missing values are excluded from the dataset.\"\n\n\nAlthough this R-Squared is good, it omits half of the data since 50% of the values for flipper_length_mm are missing. In the following code blocks, we will explore imputation of the the missing data.\n\n# Make a copy of the dataset and calculate the mean of the specific column\npenguins_Mean_imputated <- penguins_missing\n\n\n# If we only replaced the missing values for flipper_length_mm\nflipper_length_mm_mean_value <- mean(penguins$flipper_length_mm, na.rm = TRUE)\npenguins_Mean_imputated$flipper_length_mm[is.na(penguins_Mean_imputated$flipper_length_mm)] <- flipper_length_mm_mean_value\npenguins_Mean_imputated[!complete.cases(penguins), ]\n\n# A tibble: 11 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   <chr>   <chr>              <dbl>         <dbl>             <dbl>       <dbl>\n 1 Adelie  Torgersen           NA            NA                201.          NA\n 2 Adelie  Torgersen           34.1          18.1              201.        3475\n 3 Adelie  Torgersen           42            20.2              190         4250\n 4 Adelie  Torgersen           37.8          17.1              186         3300\n 5 Adelie  Torgersen           37.8          17.3              180         3700\n 6 Adelie  Dream               37.5          18.9              201.        2975\n 7 Gentoo  Biscoe              44.5          14.3              216         4100\n 8 Gentoo  Biscoe              46.2          14.4              201.        4650\n 9 Gentoo  Biscoe              47.3          13.8              201.        4725\n10 Gentoo  Biscoe              44.5          15.7              201.        4875\n11 Gentoo  Biscoe              NA            NA                201.          NA\n# ℹ 2 more variables: sex <chr>, year <dbl>\n\nregg = lm(body_mass_g~ flipper_length_mm, data = penguins_Mean_imputated, na.action=na.omit)\nprint(paste(summary(regg)$adj.r.squared, \"is the R-Squared for the linear model where missing values are imputed as the mean.\"))\n\n[1] \"0.401550181674138 is the R-Squared for the linear model where missing values are imputed as the mean.\"\n\n\nAs we can see the R-Squared dramatically decreased since we performed a basic version of imputation that just inserts one number for all missing values. Now we will proceed to impute linear model predicted values using the simputation (Loo 2022) package into the missing data set for bill_length_mm and construct the same model to achieve an increase in r-squared.\n\npenguins_imputed <- impute_lm(penguins_missing, flipper_length_mm ~ species + bill_length_mm + bill_depth_mm)\n\nregg = lm(body_mass_g~ flipper_length_mm, data = penguins_imputed)\nprint(paste(summary(regg)$adj.r.squared, \"is the R-Squared for the linear model where imputation of missing values was performed with another linear model before modeling.\"))\n\n[1] \"0.773206900379413 is the R-Squared for the linear model where imputation of missing values was performed with another linear model before modeling.\"\n\n\nAs shown in the R-Squared output for each model. We can see a small improvement in the accuracy of this model by performing imputation. This accuracy was possible since there wasnt an issue with missing values in species, bill_length_mm, and bill_depth_mm which were used to impute flipper_length_mm. But what happens if these variables contained large amounts of missing values that must be replaced as well?\n\npenguins_missing <- delete_MCAR(penguins,0.5,c(\"flipper_length_mm\",\"bill_length_mm\",\"bill_depth_mm\",\"body_mass_g\",\"species\",\"sex\"))\ntryCatch(\n  {\n  penguins_imputed_missing <- impute_lm(penguins_missing, flipper_length_mm ~ species + bill_length_mm + bill_depth_mm)\n\n  penguins_imputed_missing[!complete.cases(penguins_imputed_missing), ]\n\n  regg = lm(body_mass_g~ flipper_length_mm, data = penguins_imputed_missing)\n  print(paste(summary(regg)$adj.r.squared, \"is the R-Squared for the linear model where imputation of missing values was performed with another linear model before modeling.\"))\n  },\n  error = function(e) \n  {\n    print(\"This caused an error!\") # or whatever error handling code you want\n  }\n)\n\n[1] \"This caused an error!\"\n\n\nIt is important to note, that although it appears that we are imputing missing values in the code, the linear model fails to impute when there are missing values in the predicting variables. To avoid this error, below we will impute most of the missing data with mean or mode and attempt to impute flipper_length_mm with a linear model. This method will not be accurate due to the same underlying issue that we saw with imputing mean before.\n\npenguins_missing <- delete_MCAR(penguins,0.5,c(\"flipper_length_mm\",\"bill_length_mm\",\"bill_depth_mm\",\"body_mass_g\",\"species\",\"sex\"))\nbill_length_mm_mean_value <- mean(penguins$bill_length_mm, na.rm = TRUE)\nbill_depth_mm_mean_value <- mean(penguins$bill_depth_mm, na.rm = TRUE)\nflipper_length_mm_mean_value <- mean(penguins$flipper_length_mm, na.rm = TRUE)\nbody_mass_g_mean_value <- mean(penguins$body_mass_g, na.rm = TRUE)\nspecies_mode_value <- mode(penguins$species)\nsex_mode_value <- mode(penguins$sex)\n\n# Replace NAs in the specific column with the mean\npenguins_Mean_imputated$bill_length_mm[is.na(penguins_Mean_imputated$bill_length_mm)] <- bill_length_mm_mean_value\npenguins_Mean_imputated$bill_depth_mm[is.na(penguins_Mean_imputated$bill_depth_mm)] <- bill_depth_mm_mean_value\npenguins_Mean_imputated$flipper_length_mm[is.na(penguins_Mean_imputated$flipper_length_mm)] <- flipper_length_mm_mean_value\npenguins_Mean_imputated$body_mass_g[is.na(penguins_Mean_imputated$body_mass_g)] <- body_mass_g_mean_value\npenguins_Mean_imputated$species[is.na(penguins_Mean_imputated$species)] <- species_mode_value\npenguins_Mean_imputated$sex[is.na(penguins_Mean_imputated$sex)] <- sex_mode_value\n\npenguins_Mean_imputated[!complete.cases(penguins_Mean_imputated), ]\n\n# A tibble: 0 × 8\n# ℹ 8 variables: species <chr>, island <chr>, bill_length_mm <dbl>,\n#   bill_depth_mm <dbl>, flipper_length_mm <dbl>, body_mass_g <dbl>, sex <chr>,\n#   year <dbl>\n\npenguins_imputed <- impute_lm(penguins_Mean_imputated, flipper_length_mm ~ species + bill_length_mm + bill_depth_mm)\n\nregg = lm(body_mass_g~ flipper_length_mm, data = penguins_imputed)\nprint(paste(summary(regg)$adj.r.squared, \"is the R-Squared for the linear model where imputation of missing values was performed with another linear model before modeling.\"))\n\n[1] \"0.401560117419619 is the R-Squared for the linear model where imputation of missing values was performed with another linear model before modeling.\"\n\n\n\n\n\n\nReferences\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020. “Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data.” https://doi.org/10.5281/zenodo.3960218.\n\n\nLoo, Mark van der. 2022. “Simputation: Simple Imputation.” https://CRAN.R-project.org/package=simputation.\n\n\nRockel, Tobias. 2022. “missMethods: Methods for Missing Data.” https://CRAN.R-project.org/package=missMethods.\n\n\nWickham, Hadley. 2016. “Ggplot2: Elegant Graphics for Data Analysis.” https://ggplot2.tidyverse.org."
  },
  {
    "objectID": "methodology.html",
    "href": "methodology.html",
    "title": "3. Methodology",
    "section": "",
    "text": "Techniques for addressing missing data can be simplified into conventional approaches or brought up to date through the application of more recent methods. Although it goes without saying that the more recent methods are always preferable, there are instances in which the older methods could be useful. Also, we have to figure out why the straightforward approaches are not producing the desired results."
  },
  {
    "objectID": "methodology.html#traditional-methods",
    "href": "methodology.html#traditional-methods",
    "title": "3. Methodology",
    "section": "3.1 Traditional Methods",
    "text": "3.1 Traditional Methods\nDeleted records and single-valued imputation are two of the more traditional approaches to handling missing data [27]. In a complete-case analysis, also known as list-wise deletion, missing values are completely removed from the dataset and thrown away. As a countermeasure to the loss of data that results from list-wise deletion, pair-wise deletion eliminates only incomplete cases (Table 3).\nThis strategy is useful for addressing very few missing data in the dataset and may not introduce bias into the study. Nevertheless, doing so will deprive the research of essential information, despite the fact that this was traditionally the strategy in quantitative research that was utilized most frequently to treat missing data. Another simple solution for missing data is to impute it with a mean or median value, however doing so introduces bias into the study because it reduces the range of possible data point values.\n\nTable 3. Examples of list wise deletion and pair wise deletion [28].\nWhen it comes to imputation using linear regression, a correlation matrix is utilized in order to identify a limited number of predictors of the variables that are missing values. The variables that are the best predictors are utilized as predictor variables, and the variable that has missing data is used as the dependent variable in the regression equation. This equation is then used to make predictions about the values that are missing. Imputation based on stochastic regression is an improvement on imputation that is based on linear regression. Linear regression-based imputation involves adding random noise components to a regression line in order to restore lost variability in the data.\nThere are also general procedures, scale-item techniques, and time-series techniques that fall within the category of conventional methods.\nEnders provided a concise summary of the traditional methods for missingness mechanisms, which we may think of as a road map for dealing with missing data and which can be found in Table 4.\nIn spite of this, every one of the aforementioned approaches generates bias and does not adequately address the issue of missing data."
  },
  {
    "objectID": "methodology.html#modern-imputation-techniques",
    "href": "methodology.html#modern-imputation-techniques",
    "title": "3. Methodology",
    "section": "3.2 Modern Imputation Techniques",
    "text": "3.2 Modern Imputation Techniques\nDealing with missing values is the most difficult process since the exact nature of the missing data is unknown, which makes the task more difficult. Multiple imputations and maximum likelihood are the “state of the art” methods that have dealt with the problem of managing missing data in a satisfactory manner. The concept of multiple imputations and how they operate will be the primary focus of this dissertation.\n\nThe method known as multiple imputations [30] is widely regarded as the most effective strategy for dealing with the issue of missing data. This is because it generates numerous copies of the dataset, each of which contains a unique set of imputed values.\nMaximum-likelihood imputation [31], which is based on a variance-covariance matrix for the variables and uses all of the data points that are currently available to determine what values should be imputed for missing data.\n\nWhen applied to MCAR and MAR data, multiple imputations result in results that are objective. Using methods of multiple imputation to handle missing data has a number of advantages that come with it. The most important advantage is that using these methods reduces the amount of bias that is present in the dataset when it is analyzed. In addition to this, they improve the accuracy of the data, which in turn helps to advance the validity of an experiment that is being carried out utilizing the data. Again, when the data values within a dataset are brought closer together through the use of imputation methods, there is an increase in the precision of the data. Imputation procedures, on the other hand, contribute to a more accurate statistical analysis since they make a dataset less susceptible to being skewed by outliers.\nThe expectation-maximization algorithm and the Bayesian simulation approach are two further examples of methods [32].\n\nTable 4. Summary of traditional ways of treating missing data [29].\nIn the realm of data imputation, a relatively new method of imputation known as MICE has gained widespread acceptance [33]. As a result of this, the MICE technique, in conjunction with multiple imputations, has been investigated and utilized throughout this dissertation. In the following chapter, you will find a more in-depth discussion on the topic of multiple imputations, as well as MICE and its application to the analysis.`"
  },
  {
    "objectID": "intro.html#what-is-missing-data-and-imputation",
    "href": "intro.html#what-is-missing-data-and-imputation",
    "title": "1. Introduction",
    "section": "1.1 What is Missing Data and Imputation?",
    "text": "1.1 What is Missing Data and Imputation?\nMissing data is a critical issue that can lead to global crises and cybersecurity threats. Researchers have struggled with univariate imputation and deletion, but modern methods are being tested to find the best missing data handling solutions. Multivariate chained equation imputation is a method that prevents missing data during data collection. Bayesian posterior distribution simulation has been improved by researchers. Missing data in data analysis reduces model accuracy, and unknown data detection methods like MCAR and MAR are necessary. Single imputation and deletion are the simplest assumptions, while maximum likelihood and multiple imputation are optimal for missing data. Reliable statistical results require identifying missingness processes to ensure accurate data analysis.\nMissing completely at random (MCAR) is best described as data missing entirely at random and unrelated to observed or unobserved factors. Missing at random (MAR) describes a missing variable due to other observed variables within the data set. Missing depending on unobserved predictors (MNAR) describes the missing variable due to unobserved factors within our data set. Missingness that depends on the missing value describes missing data due to the information the participant does not want to make available.\n\nTable 1. Missing data mechanisms explained."
  },
  {
    "objectID": "intro.html#imputation",
    "href": "intro.html#imputation",
    "title": "1. Introduction",
    "section": "1.2 Imputation",
    "text": "1.2 Imputation\n“Multivariate Imputation by Chained Equation (MICE) predicts missing data using the existing data of other variables. Then it replaces missing values using the predicted values and creates a dataset called imputed dataset. By iteration, it creates multiple imputed datasets. Each dataset is then analyzed using standard statistical analysis techniques, and multiple analysis results are provided.” (Khan and Hoque 2020) The downside of this methodology is that it can be complex to implement, assumes that the data is missing at random, has a risk of overfitting, and requires many resources; however, it has the ability to impute more accurate data than single imputation based on underlying patterns in the data."
  },
  {
    "objectID": "data.html#variables",
    "href": "data.html#variables",
    "title": "2. Data",
    "section": "2.1 Variables",
    "text": "2.1 Variables\n\nSpecies - defines the species of the penguins as Adelie, Chinstrap, or Gentoo\nIsland - what island (Biscoe, Dream, or Torgersen) the penguins were found in the Palmer Archipelago, Antarctica\nBill_length_mm - a number indicating bill length in millimeters\nBill_depth_mm - a number indicating bill depth in millimeters\nFlipper_length_mm - an integer indicating flipper length in millimeters\nBody_mass_g - an integer indicating body mass in grams\nSex - a factor that marks the penguins as female or male\nYear - an integer that defines the study year as 2007, 2008, or 2009\n\nA visual depiction of how bill length and depth is measured:\n\n\n\n(Horst, Hill, and Gorman 2020) Artwork by @allison_horst"
  },
  {
    "objectID": "data.html#data-exploration",
    "href": "data.html#data-exploration",
    "title": "2. Data",
    "section": "2.2 Data Exploration",
    "text": "2.2 Data Exploration\nBelow is a summary of the palmerpenguins dataset (Horst, Hill, and Gorman 2020) using the summarytools (Comtois 2022) package and visualizations from the palmerpenguins package. (Horst, Hill, and Gorman 2020)\n\n#Shows the first six rows of the data set\nlibrary(palmerpenguins)\ndata(package = 'palmerpenguins')\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex <fct>, year <int>\n\n#Shows all the variables in the data set \nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n#Describes the penguins data set\nlibrary(summarytools)\ndescr(penguins)\n\nNon-numerical variable(s) ignored: species, island, sex\n\n\nDescriptive Statistics  \npenguins  \nN: 344  \n\n                    bill_depth_mm   bill_length_mm   body_mass_g   flipper_length_mm      year\n----------------- --------------- ---------------- ------------- ------------------- ---------\n             Mean           17.15            43.92       4201.75              200.92   2008.03\n          Std.Dev            1.97             5.46        801.95               14.06      0.82\n              Min           13.10            32.10       2700.00              172.00   2007.00\n               Q1           15.60            39.20       3550.00              190.00   2007.00\n           Median           17.30            44.45       4050.00              197.00   2008.00\n               Q3           18.70            48.50       4750.00              213.00   2009.00\n              Max           21.50            59.60       6300.00              231.00   2009.00\n              MAD            2.22             7.04        889.56               16.31      1.48\n              IQR            3.10             9.27       1200.00               23.00      2.00\n               CV            0.12             0.12          0.19                0.07      0.00\n         Skewness           -0.14             0.05          0.47                0.34     -0.05\n      SE.Skewness            0.13             0.13          0.13                0.13      0.13\n         Kurtosis           -0.92            -0.89         -0.74               -1.00     -1.51\n          N.Valid          342.00           342.00        342.00              342.00    344.00\n        Pct.Valid           99.42            99.42         99.42               99.42    100.00"
  }
]