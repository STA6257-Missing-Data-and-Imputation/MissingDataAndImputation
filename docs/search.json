[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Missing Data And Imputation",
    "section": "",
    "text": "Introduction\nAs much as researchers may attempt to eliminate or reduce missing values, datasets are rarely, if ever, perfect, which can impact the legitimacy and reliability of the results obtained. There are four main reasons for missing data: missing completely at random, missing at random, missing depending on unobserved predictors, and missingness that depends on the missing value itself.\nMissing data is a critical issue that can lead to global crises and cybersecurity threats. Researchers have struggled with univariate imputation and deletion, but modern methods are being tested to find the best missing data handling solutions. Multivariate chained equation imputation is a method that prevents missing data during data collection. Bayesian posterior distribution simulation has been improved by researchers. Missing data in data analysis reduces model accuracy, and unknown data detection methods like MCAR and MAR are necessary. Single imputation and deletion are the simplest assumptions, while maximum likelihood and multiple imputation are optimal for missing data. Reliable statistical results require identifying missingness processes to ensure accurate data analysis.\nMissing completely at random (MCAR) is best described as data missing entirely at random and unrelated to observed or unobserved factors. Missing at random (MAR) describes a missing variable due to other observed variables within the data set. Missing depending on unobserved predictors (MNAR) describes the missing variable due to unobserved factors within our data set. Missingness that depends on the missing value describes missing data due to the information the participant does not want to make available.\nWhen data is missing in a dataset, it can be handled in two ways. First would be to simply delete the missing data from the dataset. This is generally the best method if the data is missing at random and makes up for a small amount of the larger dataset. If the data is not missing at random, or if deleting it would remove a substantial amount of the data, there is a statistical technique to handle missing data known as “imputation.” The most common type of imputation is single and multiple. “In single imputation, imputed values are considered as actual values. Single imputation ignores the fact that the actual value cannot be predicted for sure by any imputation method. Single imputation based methods do not consider the uncertainty of the imputed values. Instead, they recognize the imputed values as actual values in subsequent analysis.” [1] Single imputation replaces missing values by using multiple methods, such as replacing the missing value by copying the previous participants’ value, copying over the worst value in the data set, or calculating the mean for the variable. With a single imputation, there is no distinction between observed and imputed values, which could lead to bias, influenced by outliers, can spread errors, no way to detect the imputed values, and this methodology cannot be used for complex data. Despite these drawbacks, simple imputation is one of the most popular types of imputation due to its simplicity and status as the default imputation method in many statistical packages. [2]\n“Multivariate Imputation by Chained Equation (MICE) predicts missing data using the existing data of other variables. Then it replaces missing values using the predicted values and creates a dataset called imputed dataset. By iteration, it creates multiple imputed datasets. Each dataset is then analyzed using standard statistical analysis techniques, and multiple analysis results are provided.” [1] The downside of this methodology is that it can be complex to implement, assumes that the data is missing at random, has a risk of overfitting, and requires many resources; however, it has the ability to impute more accurate data than single imputation based on underlying patterns in the data\n\nlibrary(readr)\nlibrary(lava)\nlibrary(simputation)\nlibrary(ggplot2)\n\ncats_uk <- readr::read_csv('cats_uk.csv')\ncats_uk_reference <- readr::read_csv('cats_uk_reference.csv')\n\ncats <- merge(cats_uk, cats_uk_reference, by='tag_id')\nsummary(cats_uk)\n\n    tag_id             event_id          visible       \n Length:18215       Min.   :3.396e+09   Mode :logical  \n Class :character   1st Qu.:3.459e+09   FALSE:349      \n Mode  :character   Median :3.545e+09   TRUE :17866    \n                    Mean   :3.619e+09                  \n                    3rd Qu.:3.716e+09                  \n                    Max.   :4.149e+09                  \n   timestamp                   location_long     location_lat  \n Min.   :2017-06-03 01:02:09   Min.   :-5.759   Min.   :50.10  \n 1st Qu.:2017-07-18 03:23:47   1st Qu.:-5.157   1st Qu.:50.15  \n Median :2017-08-08 03:15:41   Median :-5.073   Median :50.24  \n Mean   :2017-08-22 02:06:53   Mean   :-4.988   Mean   :50.30  \n 3rd Qu.:2017-09-20 16:38:20   3rd Qu.:-4.796   3rd Qu.:50.43  \n Max.   :2017-11-30 00:52:55   Max.   :-4.209   Max.   :50.88  \n  ground_speed    height_above_ellipsoid algorithm_marked_outlier\n Min.   :     0   Min.   :-550.07        Mode :logical           \n 1st Qu.:   396   1st Qu.:  48.87        FALSE:18004             \n Median :  1080   Median :  80.92        TRUE :211               \n Mean   :  1911   Mean   : 103.65                                \n 3rd Qu.:  2232   3rd Qu.: 119.43                                \n Max.   :277092   Max.   :8388.26                                \n manually_marked_outlier  study_name       \n Mode :logical           Length:18215      \n FALSE:18075             Class :character  \n TRUE :140               Mode  :character  \n                                           \n                                           \n                                           \n\ncats_uk_missing <- makemissing(cats_uk)\n\nggplot(cats_uk_reference, aes(hrs_indoors, prey_p_month, colour=animal_sex)) + \n  geom_count() + \n  geom_smooth(method='lm')\n\n\n\n\nReferences\n[1] S. I. Khan and A. S. M. L. Hoque, “SICE: an improved missing data imputation technique,” Journal of Big Data, vol. 7, no. 1, Jun. 2020, doi: https://doi.org/10.1186/s40537-020-00313-w.\n[2] Zhang Z. Missing data imputation: focusing on single imputation. Ann Transl Med. 2016 Jan;4(1):9. doi: 10.3978/j.issn.2305-5839.2015.12.38. PMID: 26855945; PMCID: PMC4716933.\n[3] Alruhaymi, A. and Kim, C. (2021) Study on the Missing Data Mechanisms and Imputation Methods. Open Journal of Statistics, 11, 477-492. doi: 10.4236/ojs.2021.114030"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Team",
    "section": "",
    "text": "Yoseling Gomez\nClayton Carpenter\nStesh Davis-Lewis"
  }
]