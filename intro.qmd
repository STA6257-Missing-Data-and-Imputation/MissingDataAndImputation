---
title: "1. Introduction"
bibliography: references.bib
css: styles.css
---

As much as researchers may attempt to eliminate or reduce missing values, datasets are rarely, if ever, perfect, which can impact the legitimacy and reliability of the results obtained. There are four main reasons for missing data: missing completely at random, missing at random, missing depending on unobserved predictors, and missingness that depends on the missing value itself.

When data is missing in a dataset, it can be handled in two ways. First would be to simply delete the missing data from the dataset. This is generally the best method if the data is missing at random and makes up for a small amount of the larger dataset. If the data is not missing at random, or if deleting it would remove a substantial amount of the data, there is a statistical technique to handle missing data known as "imputation." The most common type of imputation is single and multiple. Single imputation treats imputed values as actual values, disregarding the uncertainty of the real value. This method disregards the uncertainty of imputed values and acknowledges them as equivalent to true values in later analysis, disregarding the unpredictability of real values. [@khan2020] Single imputation replaces missing values by using multiple methods, such as replacing the missing value by copying the previous participants' value, copying over the worst value in the data set, or calculating the mean for the variable. With a single imputation, there is no distinction between observed and imputed values, which could lead to bias, influenced by outliers, can spread errors, no way to detect the imputed values, and this methodology cannot be used for complex data. Despite these drawbacks, simple imputation is one of the most popular types of imputation due to its simplicity and status as the default imputation method in many statistical packages. [@ATM8839]

## 1.1 What is Missing Data and Imputation?

Missing data is a critical issue that can lead to global crises and cybersecurity threats. Researchers have struggled with univariate imputation and deletion, but modern methods are being tested to find the best missing data handling solutions. Multivariate chained equation imputation is a method that prevents missing data during data collection. Bayesian posterior distribution simulation has been improved by researchers. Missing data in data analysis reduces model accuracy, and unknown data detection methods like MCAR and MAR are necessary. Single imputation and deletion are the simplest assumptions, while maximum likelihood and multiple imputation are optimal for missing data. Reliable statistical results require identifying missingness processes to ensure accurate data analysis.

Missing completely at random (MCAR) is best described as data missing entirely at random and unrelated to observed or unobserved factors. Missing at random (MAR) describes a missing variable due to other observed variables within the data set. Missing depending on unobserved predictors (MNAR) describes the missing variable due to unobserved factors within our data set. Missingness that depends on the missing value describes missing data due to the information the participant does not want to make available.

![](imgs/introFig1.png)

Table 1. Missing data mechanisms explained.

## 1.2 Imputation

MICE, or Multivariate Imputation by Chained Equation, is a method that anticipates missing data by using existing data for other variables. It creates an imputed dataset by substituting predicted values for missing values. This process generates multiple imputed datasets through iteration, which are then assessed using conventional statistical methods. The results of multiple analyses are displayed. [@khan2020] The downside of this methodology is that it can be complex to implement, assumes that the data is missing at random, has a risk of overfitting, and requires many resources; however, it has the ability to impute more accurate data than single imputation based on underlying patterns in the data.
