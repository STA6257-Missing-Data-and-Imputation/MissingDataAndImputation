---
title: "3. Methodology"
bibliography: references.bib
css: styles.css
---

Techniques for addressing missing data can be simplified into conventional approaches or brought up to date through the application of more recent methods. Although it goes without saying that the more recent methods are always preferable, there are instances in which the older methods could be useful. Also, we have to figure out why the straightforward approaches are not producing the desired results.

## 3.1 Detection of the Type of Missingness

Statistical methods for missing data assume data is MCAR. Data missingness assumptions must be checked before imputation. Methods such as Multiple Imputation by Chained Equations (MICE) are extremely dependent on the presumption that missing values are either MCAR or MAR. Verifying requires data inspection and testing.   Little's test for MCAR detection and the likelihood-ratio test for MAR were created by statisticians to help find missingness.

## 3.2 Tests of Missing Data

MCAR assumes missing data values are distributed randomly through observations. To confirm this, divide the dataset into two sets, one with missing data and the other non-missing data. If MCAR exists, use pairwise or list-wise deletion. If not, use MICE algorithm. In MAR, missing data is distributed in sub-samples. Traditional methods and tests help identify missing data mechanisms.

Little's MCAR data test is extensively used to determine if data is MCAR (Little, 1988). Little's MCAR test is the most important for missing cases. The data is considered to be MCAR and missingness is ignored if its p-value is statistically negligible. For observations with missing data values, we can use listwise deletion or the most advanced relabel imputation method, multiple imputation by chained equations, to increase the sample size and statistical power.

A likelihood-ratio test helps choose the best model from two. Diggle proposes a test for MAR assumption, but for p-value distribution under the null hypothesis, he suggests using Kolmogorov's test, as ùëùùëó acts like a uniform distribution.

## 3.3 Missing Data Imputation

There are two main types of missing data techniques: simple traditional techniques and modern techniques. Modern techniques are always better, but there are times when old techniques may work.

## 3.3.1 Traditional Methods

Older solutions for missing data include deletion and single imputation [27]. A complete-case analysis, or list-wise elimination, removes all missing values. Pair-wise deletion removes only partial cases to compensate for list-wise deletion data loss (Table 3).

This strategy helps with tiny missing data and may not skew analysis. Though it was once the most frequent way to address missing data in quantitative research, it will remove vital information. Imputing data with mean/median is another easy workaround for missing data, however it reduces data volatility and biases analysis.

![](imgs/methTable3.png)

Table 3. Examples of list wise deletion and pair wise deletion

A correlation matrix identifies a few missing variable predictors for linear regression imputation. In the regression equation, the best predictors are predictor variables and the variable with missing data is the dependent variable. This predicts missing values. Linear regression-based imputation adds random noise terms to a regression line to restore data variability. Stochastic regression improves this.

General, scale-item, and time-series methods are also traditional.

See Table 4 for Enders' summary of classic missingness procedures as a road map for handling missing data.

All of the above strategies contain bias and fail to address missing data.

Deleted records and single-valued imputation are two of the more traditional approaches to handling missing data [@alruhaymi2021]. In a complete-case analysis, also known as list-wise deletion, missing values are completely removed from the dataset and thrown away. As a countermeasure to the loss of data that results from list-wise deletion, pair-wise deletion eliminates only incomplete cases (Table 3).
Older solutions for missing data include deletion and single imputation [27]. A complete-case analysis, or list-wise elimination, removes all missing values. Pair-wise deletion removes only partial cases to compensate for list-wise deletion data loss (Table 3).

This strategy helps with tiny missing data and may not skew analysis. Though it was once the most frequent way to address missing data in quantitative research, it will remove vital information. Imputing data with mean/median is another easy workaround for missing data, however it reduces data volatility and biases analysis.

A correlation matrix identifies a few missing variable predictors for linear regression imputation. In the regression equation, the best predictors are predictor variables and the variable with missing data is the dependent variable. This predicts missing values. Linear regression-based imputation adds random noise terms to a regression line to restore data variability. Stochastic regression improves this.

See Table 4 for Enders' summary of classic missingness procedures as a road map for handling missing data.

All of the above strategies contain bias and fail to address missing data.

## 3.3.2 Modern Imputation Techniques

Dealing with missing values is the most difficult process since the exact nature of the missing data is unknown, which makes the task more difficult. Multiple imputations and maximum likelihood are the "state of the art" methods that have dealt with the problem of managing missing data in a satisfactory manner. The concept of multiple imputations and how they operate will be the primary focus of this dissertation.

1)  The method known as multiple imputations [@alruhaymi2021] is widely regarded as the most effective strategy for dealing with the issue of missing data. This is because it generates numerous copies of the dataset, each of which contains a unique set of imputed values.

2)  Maximum-likelihood imputation, which is based on a variance-covariance matrix for the variables and uses all of the data points that are currently available to determine what values should be imputed for missing data.

When applied to MCAR and MAR data, multiple imputations result in results that are objective. Using methods of multiple imputation to handle missing data has a number of advantages that come with it. The most important advantage is that using these methods reduces the amount of bias that is present in the dataset when it is analyzed. In addition to this, they improve the accuracy of the data, which in turn helps to advance the validity of an experiment that is being carried out utilizing the data. Again, when the data values within a dataset are brought closer together through the use of imputation methods, there is an increase in the precision of the data. Imputation procedures, on the other hand, contribute to a more accurate statistical analysis since they make a dataset less susceptible to being skewed by outliers.

The expectation-maximization algorithm and the Bayesian simulation approach are two further examples of methods [@alruhaymi2021].

![](imgs/methTable4.png)

Table 4. Summary of traditional ways of treating missing data [@alruhaymi2021].

Multiple imputation works effectively with and especially with MCAR or MAR missing data. The sample size is maintained and selection is avoided by not dropping cases with incomplete data. It also lowers standard error bias. Imputed data analysis involves imputing missing values, theoretical analysis, and pooling estimations into a single set of results. First, impute missing values to generate enough data sets. Increasing the percentage of missing data requires more imputations. Each imputation creates new data. Step two is examining imputed data in the researcher's theory-based model. This requires simultaneous processing of each imputed data set. Researcher must specify imputed data in most statistical applications. The final step is pooling findings. Pooling produces a single result that combines imputation uncertainty into standard errors.
